{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping a word to it's base word\n",
    "- talking -> talk\n",
    "- adjustable -> adjust\n",
    "- flying -> fly\n",
    "etc.\n",
    "\n",
    "### This process is called Stemming. The base word is called lemma. And the use of knowledge of a particular language to derive the base word is called Lemmatization.\n",
    "\n",
    "Lemmatization is a more advanced process and is language specific. It is more accurate than stemming. But it is computationally expensive and takes more time than stemming. However both have their different use cases.\n",
    "\n",
    "### In this notebook, I will be using the NLTK library to perform lemmatization on the text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "talking  --->  talk\n",
      "adjustable  --->  adjust\n",
      "flying  --->  fli\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "words = ['talking', 'adjustable', 'flying']\n",
    "\n",
    "#we can see that all the answers are not correct here, the stemmer only uses fixed rules and lacks linguistic ability\n",
    "for word in words:\n",
    "    print(word, ' ---> ', stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating  |  eat\n",
      "eat  |  eat\n",
      "talk  |  talk\n",
      "ate  |  eat\n",
      "adjustable  |  adjustable\n",
      "rat  |  rat\n",
      "meeting  |  meet\n",
      "better  |  well\n",
      "ability  |  ability\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "doc = nlp('eating eat talk ate adjustable rat meeting better ability')\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text, ' | ', token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bro  |  Brother\n",
      ",  |  ,\n",
      "you  |  you\n",
      "wanna  |  wanna\n",
      "hit  |  hit\n",
      "chest  |  chest\n",
      "today  |  today\n",
      "?  |  ?\n",
      "Hell  |  hell\n",
      "yeah  |  yeah\n",
      ",  |  ,\n",
      "bruv  |  Brother\n"
     ]
    }
   ],
   "source": [
    "# adding custom rule\n",
    "ar = nlp.get_pipe('attribute_ruler')\n",
    "ar.add([[{'TEXT':'Bro'}],[{'TEXT':'Bruv'}]],{'LEMMA':'Brother'})\n",
    "\n",
    "doc = nlp(\"Bro, you wanna hit chest today? Hell yeah, bruv\")\n",
    "\n",
    "for token in doc:\n",
    "\n",
    "    print(token.text, ' | ', token.lemma_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parts of Speect tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elon  |  PROPN  |  proper noun  |  NNP  |  noun, proper singular\n",
      "flew  |  VERB  |  verb  |  VBD  |  verb, past tense\n",
      "to  |  ADP  |  adposition  |  IN  |  conjunction, subordinating or preposition\n",
      "mars  |  NOUN  |  noun  |  NNS  |  noun, plural\n",
      "yesterday  |  NOUN  |  noun  |  NN  |  noun, singular or mass\n",
      ".  |  PUNCT  |  punctuation  |  .  |  punctuation mark, sentence closer\n",
      "He  |  PRON  |  pronoun  |  PRP  |  pronoun, personal\n",
      "forgot  |  VERB  |  verb  |  VBD  |  verb, past tense\n",
      "to  |  PART  |  particle  |  TO  |  infinitival \"to\"\n",
      "carry  |  VERB  |  verb  |  VB  |  verb, base form\n",
      "his  |  PRON  |  pronoun  |  PRP$  |  pronoun, possessive\n",
      "mobile  |  ADJ  |  adjective  |  JJ  |  adjective (English), other noun-modifier (Chinese)\n",
      "phone  |  NOUN  |  noun  |  NN  |  noun, singular or mass\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "doc = nlp('Elon flew to mars yesterday. He forgot to carry his mobile phone')\n",
    "\n",
    "for token in doc:\n",
    "    print(token, ' | ', token.pos_ , ' | ', spacy.explain(token.pos_) , ' | ', token.tag_ , ' | ', spacy.explain(token.tag_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"REDMOND, Wash. — April 25, 2024 — Microsoft Corp. today announced the following results for the quarter ended March 31, 2024, as compared to the corresponding period of last fiscal year:\n",
    "\n",
    "·        Revenue was $61.9 billion and increased 17%\n",
    "\n",
    "·        Operating income was $27.6 billion and increased 23%\n",
    "\n",
    "·        Net income was $21.9 billion and increased 20%\n",
    "\n",
    "·        Diluted earnings per share was $2.94 and increased 20%\n",
    "\n",
    "“Microsoft Copilot and Copilot stack are orchestrating a new era of AI transformation, driving better business outcomes across every role and industry,\" said Satya Nadella, chairman and chief executive officer of Microsoft.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REDMOND  |  PROPN | proper noun\n",
      "Wash.  |  PROPN | proper noun\n",
      "April  |  PROPN | proper noun\n",
      "25  |  NUM | numeral\n",
      "2024  |  NUM | numeral\n",
      "Microsoft  |  PROPN | proper noun\n",
      "Corp.  |  PROPN | proper noun\n",
      "today  |  NOUN | noun\n",
      "announced  |  VERB | verb\n",
      "the  |  DET | determiner\n",
      "following  |  VERB | verb\n",
      "results  |  NOUN | noun\n",
      "for  |  ADP | adposition\n",
      "the  |  DET | determiner\n",
      "quarter  |  NOUN | noun\n",
      "ended  |  VERB | verb\n",
      "March  |  PROPN | proper noun\n",
      "31  |  NUM | numeral\n",
      "2024  |  NUM | numeral\n",
      "as  |  SCONJ | subordinating conjunction\n",
      "compared  |  VERB | verb\n",
      "to  |  ADP | adposition\n",
      "the  |  DET | determiner\n",
      "corresponding  |  ADJ | adjective\n",
      "period  |  NOUN | noun\n",
      "of  |  ADP | adposition\n",
      "last  |  ADJ | adjective\n",
      "fiscal  |  ADJ | adjective\n",
      "year  |  NOUN | noun\n",
      "Revenue  |  NOUN | noun\n",
      "was  |  AUX | auxiliary\n",
      "$  |  SYM | symbol\n",
      "61.9  |  NUM | numeral\n",
      "billion  |  NUM | numeral\n",
      "and  |  CCONJ | coordinating conjunction\n",
      "increased  |  VERB | verb\n",
      "17  |  NUM | numeral\n",
      "%  |  NOUN | noun\n",
      "Operating  |  VERB | verb\n",
      "income  |  NOUN | noun\n",
      "was  |  AUX | auxiliary\n",
      "$  |  SYM | symbol\n",
      "27.6  |  NUM | numeral\n",
      "billion  |  NUM | numeral\n",
      "and  |  CCONJ | coordinating conjunction\n",
      "increased  |  VERB | verb\n",
      "23  |  NUM | numeral\n",
      "%  |  NOUN | noun\n",
      "Net  |  ADJ | adjective\n",
      "income  |  NOUN | noun\n",
      "was  |  AUX | auxiliary\n",
      "$  |  SYM | symbol\n",
      "21.9  |  NUM | numeral\n",
      "billion  |  NUM | numeral\n",
      "and  |  CCONJ | coordinating conjunction\n",
      "increased  |  VERB | verb\n",
      "20  |  NUM | numeral\n",
      "%  |  NOUN | noun\n",
      "Diluted  |  VERB | verb\n",
      "earnings  |  NOUN | noun\n",
      "per  |  ADP | adposition\n",
      "share  |  NOUN | noun\n",
      "was  |  AUX | auxiliary\n",
      "$  |  SYM | symbol\n",
      "2.94  |  NUM | numeral\n",
      "and  |  CCONJ | coordinating conjunction\n",
      "increased  |  VERB | verb\n",
      "20  |  NUM | numeral\n",
      "%  |  NOUN | noun\n",
      "Microsoft  |  PROPN | proper noun\n",
      "Copilot  |  PROPN | proper noun\n",
      "and  |  CCONJ | coordinating conjunction\n",
      "Copilot  |  NOUN | noun\n",
      "stack  |  NOUN | noun\n",
      "are  |  AUX | auxiliary\n",
      "orchestrating  |  VERB | verb\n",
      "a  |  DET | determiner\n",
      "new  |  ADJ | adjective\n",
      "era  |  NOUN | noun\n",
      "of  |  ADP | adposition\n",
      "AI  |  PROPN | proper noun\n",
      "transformation  |  NOUN | noun\n",
      "driving  |  VERB | verb\n",
      "better  |  ADJ | adjective\n",
      "business  |  NOUN | noun\n",
      "outcomes  |  NOUN | noun\n",
      "across  |  ADP | adposition\n",
      "every  |  DET | determiner\n",
      "role  |  NOUN | noun\n",
      "and  |  CCONJ | coordinating conjunction\n",
      "industry  |  NOUN | noun\n",
      "said  |  VERB | verb\n",
      "Satya  |  PROPN | proper noun\n",
      "Nadella  |  PROPN | proper noun\n",
      "chairman  |  NOUN | noun\n",
      "and  |  CCONJ | coordinating conjunction\n",
      "chief  |  ADJ | adjective\n",
      "executive  |  ADJ | adjective\n",
      "officer  |  NOUN | noun\n",
      "of  |  ADP | adposition\n",
      "Microsoft  |  PROPN | proper noun\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(text=text)\n",
    "for token in doc:\n",
    "    if token.pos_ not in ['SPACE','X','PUNCT']:\n",
    "        print(token.text, ' | ', token.pos_, '|', spacy.explain(token.pos_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{96: 12,\n",
       " 97: 17,\n",
       " 93: 15,\n",
       " 92: 24,\n",
       " 100: 13,\n",
       " 90: 5,\n",
       " 85: 7,\n",
       " 98: 1,\n",
       " 84: 8,\n",
       " 103: 9,\n",
       " 87: 5,\n",
       " 99: 4,\n",
       " 89: 7}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy.attrs\n",
    "\n",
    "#IMP\n",
    "count = doc.count_by(spacy.attrs.POS)\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROPN  --> 12\n",
      "PUNCT  --> 17\n",
      "NUM  --> 15\n",
      "NOUN  --> 24\n",
      "VERB  --> 13\n",
      "DET  --> 5\n",
      "ADP  --> 7\n",
      "SCONJ  --> 1\n",
      "ADJ  --> 8\n",
      "SPACE  --> 9\n",
      "AUX  --> 5\n",
      "SYM  --> 4\n",
      "CCONJ  --> 7\n"
     ]
    }
   ],
   "source": [
    "for key in count:\n",
    "    print(doc.vocab[key].text,' -->',count[key])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonMachineLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
